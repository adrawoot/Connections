{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbFfzvMGQhh2"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCmRMPDHQhh3"
      },
      "source": [
        "[Learn the Basics](intro.html) \\|\\| **Quickstart** \\|\\|\n",
        "[Tensors](tensorqs_tutorial.html) \\|\\| [Datasets &\n",
        "DataLoaders](data_tutorial.html) \\|\\|\n",
        "[Transforms](transforms_tutorial.html) \\|\\| [Build\n",
        "Model](buildmodel_tutorial.html) \\|\\|\n",
        "[Autograd](autogradqs_tutorial.html) \\|\\|\n",
        "[Optimization](optimization_tutorial.html) \\|\\| [Save & Load\n",
        "Model](saveloadrun_tutorial.html)\n",
        "\n",
        "Quickstart\n",
        "==========\n",
        "\n",
        "This section runs through the API for common tasks in machine learning.\n",
        "Refer to the links in each section to dive deeper.\n",
        "\n",
        "Working with data\n",
        "-----------------\n",
        "\n",
        "PyTorch has two [primitives to work with\n",
        "data](https://pytorch.org/docs/stable/data.html):\n",
        "`torch.utils.data.DataLoader` and `torch.utils.data.Dataset`. `Dataset`\n",
        "stores the samples and their corresponding labels, and `DataLoader`\n",
        "wraps an iterable around the `Dataset`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-9929l_1Qhh4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCzhWDKqQhh4"
      },
      "source": [
        "PyTorch offers domain-specific libraries such as\n",
        "[TorchText](https://pytorch.org/text/stable/index.html),\n",
        "[TorchVision](https://pytorch.org/vision/stable/index.html), and\n",
        "[TorchAudio](https://pytorch.org/audio/stable/index.html), all of which\n",
        "include datasets. For this tutorial, we will be using a TorchVision\n",
        "dataset.\n",
        "\n",
        "The `torchvision.datasets` module contains `Dataset` objects for many\n",
        "real-world vision data like CIFAR, COCO ([full list\n",
        "here](https://pytorch.org/vision/stable/datasets.html)). In this\n",
        "tutorial, we use the FashionMNIST dataset. Every TorchVision `Dataset`\n",
        "includes two arguments: `transform` and `target_transform` to modify the\n",
        "samples and labels respectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uZVuMOxIQhh5",
        "outputId": "a7dad932-25e5-4dc6-c441-94c598dd2c3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 9.02MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 198kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.64MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 6.00MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui8Qbje1Qhh5"
      },
      "source": [
        "We pass the `Dataset` as an argument to `DataLoader`. This wraps an\n",
        "iterable over our dataset, and supports automatic batching, sampling,\n",
        "shuffling and multiprocess data loading. Here we define a batch size of\n",
        "64, i.e. each element in the dataloader iterable will return a batch of\n",
        "64 features and labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pAiWLOTmQhh5",
        "outputId": "f209926b-dfe5-4f49-888c-c2e328aca17d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngRfE0FpQhh5"
      },
      "source": [
        "Read more about [loading data in PyTorch](data_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGlTZIDIQhh5"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_g1Js58Qhh5"
      },
      "source": [
        "Creating Models\n",
        "===============\n",
        "\n",
        "To define a neural network in PyTorch, we create a class that inherits\n",
        "from\n",
        "[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n",
        "We define the layers of the network in the `__init__` function and\n",
        "specify how data will pass through the network in the `forward`\n",
        "function. To accelerate operations in the neural network, we move it to\n",
        "the GPU or MPS if available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yUv8EWn-Qhh5",
        "outputId": "2c15be5f-4fa3-4b08-95a7-3731fbe3181c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzCBqZPHQhh5"
      },
      "source": [
        "Read more about [building neural networks in\n",
        "PyTorch](buildmodel_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXcVaeyXQhh6"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6dtPdjhQhh6"
      },
      "source": [
        "Optimizing the Model Parameters\n",
        "===============================\n",
        "\n",
        "To train a model, we need a [loss\n",
        "function](https://pytorch.org/docs/stable/nn.html#loss-functions) and an\n",
        "[optimizer](https://pytorch.org/docs/stable/optim.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UilkLcFRQhh6"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R66YJ_QQhh6"
      },
      "source": [
        "In a single training loop, the model makes predictions on the training\n",
        "dataset (fed to it in batches), and backpropagates the prediction error\n",
        "to adjust the model\\'s parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6486DrurQhh6"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD-nrINUQhh6"
      },
      "source": [
        "We also check the model\\'s performance against the test dataset to\n",
        "ensure it is learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9hbCfWQ9Qhh6"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3WkSNLRQhh6"
      },
      "source": [
        "The training process is conducted over several iterations (*epochs*).\n",
        "During each epoch, the model learns parameters to make better\n",
        "predictions. We print the model\\'s accuracy and loss at each epoch;\n",
        "we\\'d like to see the accuracy increase and the loss decrease with every\n",
        "epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dVRk8_DnQhh6",
        "outputId": "716e6b91-1c4d-48ff-c660-5392277224ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.601284  [   64/60000]\n",
            "loss: 0.709030  [ 6464/60000]\n",
            "loss: 0.486299  [12864/60000]\n",
            "loss: 0.719938  [19264/60000]\n",
            "loss: 0.639393  [25664/60000]\n",
            "loss: 0.620995  [32064/60000]\n",
            "loss: 0.685446  [38464/60000]\n",
            "loss: 0.707583  [44864/60000]\n",
            "loss: 0.678571  [51264/60000]\n",
            "loss: 0.673049  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 77.1%, Avg loss: 0.654408 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.601284  [   64/60000]\n",
            "loss: 0.709030  [ 6464/60000]\n",
            "loss: 0.486299  [12864/60000]\n",
            "loss: 0.719938  [19264/60000]\n",
            "loss: 0.639393  [25664/60000]\n",
            "loss: 0.620995  [32064/60000]\n",
            "loss: 0.685446  [38464/60000]\n",
            "loss: 0.707583  [44864/60000]\n",
            "loss: 0.678571  [51264/60000]\n",
            "loss: 0.673049  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 77.1%, Avg loss: 0.654408 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.601284  [   64/60000]\n",
            "loss: 0.709030  [ 6464/60000]\n",
            "loss: 0.486299  [12864/60000]\n",
            "loss: 0.719938  [19264/60000]\n",
            "loss: 0.639393  [25664/60000]\n",
            "loss: 0.620995  [32064/60000]\n",
            "loss: 0.685446  [38464/60000]\n",
            "loss: 0.707583  [44864/60000]\n",
            "loss: 0.678571  [51264/60000]\n",
            "loss: 0.673049  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 77.1%, Avg loss: 0.654408 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.601284  [   64/60000]\n",
            "loss: 0.709030  [ 6464/60000]\n",
            "loss: 0.486299  [12864/60000]\n",
            "loss: 0.719938  [19264/60000]\n",
            "loss: 0.639393  [25664/60000]\n",
            "loss: 0.620995  [32064/60000]\n",
            "loss: 0.685446  [38464/60000]\n",
            "loss: 0.707583  [44864/60000]\n",
            "loss: 0.678571  [51264/60000]\n",
            "loss: 0.673049  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 77.1%, Avg loss: 0.654408 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.601284  [   64/60000]\n",
            "loss: 0.709030  [ 6464/60000]\n",
            "loss: 0.486299  [12864/60000]\n",
            "loss: 0.719938  [19264/60000]\n",
            "loss: 0.639393  [25664/60000]\n",
            "loss: 0.620995  [32064/60000]\n",
            "loss: 0.685446  [38464/60000]\n",
            "loss: 0.707583  [44864/60000]\n",
            "loss: 0.678571  [51264/60000]\n",
            "loss: 0.673049  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 77.1%, Avg loss: 0.654408 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discussion:**\n",
        "</br>\n",
        "The accuracy improved from 68.3% to 77.1% in the first 5 epochs, showing that the model was learning effectively. After 5 epochs, the accuracy plateaued at 77.1%, meaning further training didn’t improve the results. This suggests that 5 epochs were enough for the model to converge, and training longer only wasted computational resources without any benefit."
      ],
      "metadata": {
        "id": "R_ZxWl7CUhX6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E541MqlQhh6"
      },
      "source": [
        "Read more about [Training your model](optimization_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4FA3YJMQhh6"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7lMOpRCQhh7"
      },
      "source": [
        "Saving Models\n",
        "=============\n",
        "\n",
        "A common way to save a model is to serialize the internal state\n",
        "dictionary (containing the model parameters).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "67xpwk0uQhh7",
        "outputId": "1878c35b-2ce6-4a12-b3c7-c34b30b88111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsjDAfMYQhh7"
      },
      "source": [
        "Loading Models\n",
        "==============\n",
        "\n",
        "The process for loading a model includes re-creating the model structure\n",
        "and loading the state dictionary into it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EPHSSwokQhh7",
        "outputId": "30feab94-bab8-4a1e-89b6-7745f3bf0dce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxKoKKK-Qhh7"
      },
      "source": [
        "This model can now be used to make predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "e5MENoshQhh7",
        "outputId": "4c3c63e4-9118-4d16-cf02-401afc0d7ad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ],
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNetwork1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 1024),  # Increased hidden layer size\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 10)     # Output layer remains the same\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = MyNetwork1().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8eEnWmpLXgMG",
        "outputId": "7170a3e9-66ee-440e-8bc9-64c345fe0d76"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyNetwork1(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=1024, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=1024, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyNetwork1().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
        "\n",
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HlEwH5oWYp9a",
        "outputId": "d019b6b3-6c84-46df-c779-90d93ddf8947"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.322689  [   64/60000]\n",
            "loss: 2.105378  [ 6464/60000]\n",
            "loss: 1.652731  [12864/60000]\n",
            "loss: 1.378951  [19264/60000]\n",
            "loss: 1.036821  [25664/60000]\n",
            "loss: 0.955205  [32064/60000]\n",
            "loss: 0.948035  [38464/60000]\n",
            "loss: 0.818610  [44864/60000]\n",
            "loss: 0.833212  [51264/60000]\n",
            "loss: 0.771693  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 72.7%, Avg loss: 0.755300 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.747797  [   64/60000]\n",
            "loss: 0.806851  [ 6464/60000]\n",
            "loss: 0.553385  [12864/60000]\n",
            "loss: 0.752311  [19264/60000]\n",
            "loss: 0.642289  [25664/60000]\n",
            "loss: 0.613460  [32064/60000]\n",
            "loss: 0.684041  [38464/60000]\n",
            "loss: 0.659472  [44864/60000]\n",
            "loss: 0.695873  [51264/60000]\n",
            "loss: 0.620670  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 78.9%, Avg loss: 0.609907 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.533922  [   64/60000]\n",
            "loss: 0.625997  [ 6464/60000]\n",
            "loss: 0.420797  [12864/60000]\n",
            "loss: 0.638461  [19264/60000]\n",
            "loss: 0.560319  [25664/60000]\n",
            "loss: 0.535612  [32064/60000]\n",
            "loss: 0.582276  [38464/60000]\n",
            "loss: 0.633464  [44864/60000]\n",
            "loss: 0.670820  [51264/60000]\n",
            "loss: 0.537800  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.2%, Avg loss: 0.556900 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.448970  [   64/60000]\n",
            "loss: 0.548614  [ 6464/60000]\n",
            "loss: 0.366353  [12864/60000]\n",
            "loss: 0.577255  [19264/60000]\n",
            "loss: 0.506300  [25664/60000]\n",
            "loss: 0.494014  [32064/60000]\n",
            "loss: 0.535340  [38464/60000]\n",
            "loss: 0.633971  [44864/60000]\n",
            "loss: 0.650914  [51264/60000]\n",
            "loss: 0.481883  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.9%, Avg loss: 0.530079 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.396714  [   64/60000]\n",
            "loss: 0.509542  [ 6464/60000]\n",
            "loss: 0.334537  [12864/60000]\n",
            "loss: 0.537407  [19264/60000]\n",
            "loss: 0.471256  [25664/60000]\n",
            "loss: 0.468425  [32064/60000]\n",
            "loss: 0.504689  [38464/60000]\n",
            "loss: 0.626290  [44864/60000]\n",
            "loss: 0.625965  [51264/60000]\n",
            "loss: 0.448921  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.5%, Avg loss: 0.511961 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Run 1, the accuracy stayed at 77.1% across all 5 epochs, showing no improvement after the first epoch. In Run 2, accuracy improved from 72.7% to 81.5% over 5 epochs, and the loss steadily decreased. The changes in the network architecture or training parameters in Run 2 helped the model learn better and generalize more effectively, leading to higher accuracy."
      ],
      "metadata": {
        "id": "6KN7CHVifZCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNetwork2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = MyNetwork2().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rmZaK5XGgCST",
        "outputId": "8ffd1e2a-234a-4cc6-debc-d1e669b00832"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyNetwork2(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU()\n",
            "    (9): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (10): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU()\n",
            "    (12): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "model = MyNetwork2().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "    scheduler.step()\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ts0PILe7gOl9",
        "outputId": "f341e8e5-7dee-4ab6-c277-effb2c32b54d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.277439  [   64/60000]\n",
            "loss: 0.510960  [ 6464/60000]\n",
            "loss: 0.417089  [12864/60000]\n",
            "loss: 0.536605  [19264/60000]\n",
            "loss: 0.512476  [25664/60000]\n",
            "loss: 0.441637  [32064/60000]\n",
            "loss: 0.338571  [38464/60000]\n",
            "loss: 0.508354  [44864/60000]\n",
            "loss: 0.385761  [51264/60000]\n",
            "loss: 0.452407  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.9%, Avg loss: 0.418262 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.392558  [   64/60000]\n",
            "loss: 0.333193  [ 6464/60000]\n",
            "loss: 0.297315  [12864/60000]\n",
            "loss: 0.310737  [19264/60000]\n",
            "loss: 0.363921  [25664/60000]\n",
            "loss: 0.341404  [32064/60000]\n",
            "loss: 0.268131  [38464/60000]\n",
            "loss: 0.395197  [44864/60000]\n",
            "loss: 0.318056  [51264/60000]\n",
            "loss: 0.358000  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.7%, Avg loss: 0.378293 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.260457  [   64/60000]\n",
            "loss: 0.346317  [ 6464/60000]\n",
            "loss: 0.227383  [12864/60000]\n",
            "loss: 0.259849  [19264/60000]\n",
            "loss: 0.331448  [25664/60000]\n",
            "loss: 0.298841  [32064/60000]\n",
            "loss: 0.256750  [38464/60000]\n",
            "loss: 0.329839  [44864/60000]\n",
            "loss: 0.303736  [51264/60000]\n",
            "loss: 0.329434  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.2%, Avg loss: 0.366364 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.251931  [   64/60000]\n",
            "loss: 0.276334  [ 6464/60000]\n",
            "loss: 0.218216  [12864/60000]\n",
            "loss: 0.205016  [19264/60000]\n",
            "loss: 0.313075  [25664/60000]\n",
            "loss: 0.264166  [32064/60000]\n",
            "loss: 0.185646  [38464/60000]\n",
            "loss: 0.288755  [44864/60000]\n",
            "loss: 0.281227  [51264/60000]\n",
            "loss: 0.317866  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.2%, Avg loss: 0.378566 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.232396  [   64/60000]\n",
            "loss: 0.281027  [ 6464/60000]\n",
            "loss: 0.195658  [12864/60000]\n",
            "loss: 0.199661  [19264/60000]\n",
            "loss: 0.288976  [25664/60000]\n",
            "loss: 0.242367  [32064/60000]\n",
            "loss: 0.160024  [38464/60000]\n",
            "loss: 0.250992  [44864/60000]\n",
            "loss: 0.278146  [51264/60000]\n",
            "loss: 0.255683  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.9%, Avg loss: 0.364453 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.211308  [   64/60000]\n",
            "loss: 0.205486  [ 6464/60000]\n",
            "loss: 0.188867  [12864/60000]\n",
            "loss: 0.181901  [19264/60000]\n",
            "loss: 0.212955  [25664/60000]\n",
            "loss: 0.184748  [32064/60000]\n",
            "loss: 0.177454  [38464/60000]\n",
            "loss: 0.192210  [44864/60000]\n",
            "loss: 0.212462  [51264/60000]\n",
            "loss: 0.234665  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.8%, Avg loss: 0.357811 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.189688  [   64/60000]\n",
            "loss: 0.190652  [ 6464/60000]\n",
            "loss: 0.164802  [12864/60000]\n",
            "loss: 0.150381  [19264/60000]\n",
            "loss: 0.182359  [25664/60000]\n",
            "loss: 0.165239  [32064/60000]\n",
            "loss: 0.153372  [38464/60000]\n",
            "loss: 0.169078  [44864/60000]\n",
            "loss: 0.166366  [51264/60000]\n",
            "loss: 0.144323  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.6%, Avg loss: 0.385638 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.181071  [   64/60000]\n",
            "loss: 0.172974  [ 6464/60000]\n",
            "loss: 0.138352  [12864/60000]\n",
            "loss: 0.111140  [19264/60000]\n",
            "loss: 0.183750  [25664/60000]\n",
            "loss: 0.141967  [32064/60000]\n",
            "loss: 0.140943  [38464/60000]\n",
            "loss: 0.153819  [44864/60000]\n",
            "loss: 0.143545  [51264/60000]\n",
            "loss: 0.131889  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.4%, Avg loss: 0.425196 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.175500  [   64/60000]\n",
            "loss: 0.126139  [ 6464/60000]\n",
            "loss: 0.147817  [12864/60000]\n",
            "loss: 0.090283  [19264/60000]\n",
            "loss: 0.161563  [25664/60000]\n",
            "loss: 0.119673  [32064/60000]\n",
            "loss: 0.160069  [38464/60000]\n",
            "loss: 0.111187  [44864/60000]\n",
            "loss: 0.134045  [51264/60000]\n",
            "loss: 0.104509  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.7%, Avg loss: 0.436687 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.156849  [   64/60000]\n",
            "loss: 0.120023  [ 6464/60000]\n",
            "loss: 0.142362  [12864/60000]\n",
            "loss: 0.076021  [19264/60000]\n",
            "loss: 0.176178  [25664/60000]\n",
            "loss: 0.112817  [32064/60000]\n",
            "loss: 0.130124  [38464/60000]\n",
            "loss: 0.114277  [44864/60000]\n",
            "loss: 0.073880  [51264/60000]\n",
            "loss: 0.078859  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.7%, Avg loss: 0.466832 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.129508  [   64/60000]\n",
            "loss: 0.106519  [ 6464/60000]\n",
            "loss: 0.138697  [12864/60000]\n",
            "loss: 0.058365  [19264/60000]\n",
            "loss: 0.082871  [25664/60000]\n",
            "loss: 0.093383  [32064/60000]\n",
            "loss: 0.123220  [38464/60000]\n",
            "loss: 0.048665  [44864/60000]\n",
            "loss: 0.127062  [51264/60000]\n",
            "loss: 0.131290  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.2%, Avg loss: 0.425070 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.076039  [   64/60000]\n",
            "loss: 0.093966  [ 6464/60000]\n",
            "loss: 0.121630  [12864/60000]\n",
            "loss: 0.041473  [19264/60000]\n",
            "loss: 0.056937  [25664/60000]\n",
            "loss: 0.070270  [32064/60000]\n",
            "loss: 0.117712  [38464/60000]\n",
            "loss: 0.045891  [44864/60000]\n",
            "loss: 0.062219  [51264/60000]\n",
            "loss: 0.044859  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.2%, Avg loss: 0.467225 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.079545  [   64/60000]\n",
            "loss: 0.058205  [ 6464/60000]\n",
            "loss: 0.092841  [12864/60000]\n",
            "loss: 0.034547  [19264/60000]\n",
            "loss: 0.041619  [25664/60000]\n",
            "loss: 0.046315  [32064/60000]\n",
            "loss: 0.110682  [38464/60000]\n",
            "loss: 0.020406  [44864/60000]\n",
            "loss: 0.060983  [51264/60000]\n",
            "loss: 0.022414  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.0%, Avg loss: 0.515431 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.067844  [   64/60000]\n",
            "loss: 0.030140  [ 6464/60000]\n",
            "loss: 0.086122  [12864/60000]\n",
            "loss: 0.021003  [19264/60000]\n",
            "loss: 0.030819  [25664/60000]\n",
            "loss: 0.037642  [32064/60000]\n",
            "loss: 0.072422  [38464/60000]\n",
            "loss: 0.012482  [44864/60000]\n",
            "loss: 0.032287  [51264/60000]\n",
            "loss: 0.021527  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.0%, Avg loss: 0.563109 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.056949  [   64/60000]\n",
            "loss: 0.024164  [ 6464/60000]\n",
            "loss: 0.070082  [12864/60000]\n",
            "loss: 0.040983  [19264/60000]\n",
            "loss: 0.015527  [25664/60000]\n",
            "loss: 0.062225  [32064/60000]\n",
            "loss: 0.064238  [38464/60000]\n",
            "loss: 0.028984  [44864/60000]\n",
            "loss: 0.023947  [51264/60000]\n",
            "loss: 0.013642  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.0%, Avg loss: 0.605657 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.081707  [   64/60000]\n",
            "loss: 0.006970  [ 6464/60000]\n",
            "loss: 0.025379  [12864/60000]\n",
            "loss: 0.012353  [19264/60000]\n",
            "loss: 0.020938  [25664/60000]\n",
            "loss: 0.018525  [32064/60000]\n",
            "loss: 0.044191  [38464/60000]\n",
            "loss: 0.012748  [44864/60000]\n",
            "loss: 0.042037  [51264/60000]\n",
            "loss: 0.020248  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.5%, Avg loss: 0.573342 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.049883  [   64/60000]\n",
            "loss: 0.009503  [ 6464/60000]\n",
            "loss: 0.008808  [12864/60000]\n",
            "loss: 0.005676  [19264/60000]\n",
            "loss: 0.010111  [25664/60000]\n",
            "loss: 0.014187  [32064/60000]\n",
            "loss: 0.038523  [38464/60000]\n",
            "loss: 0.009458  [44864/60000]\n",
            "loss: 0.010469  [51264/60000]\n",
            "loss: 0.007273  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.5%, Avg loss: 0.601080 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.026198  [   64/60000]\n",
            "loss: 0.003633  [ 6464/60000]\n",
            "loss: 0.007138  [12864/60000]\n",
            "loss: 0.004371  [19264/60000]\n",
            "loss: 0.002935  [25664/60000]\n",
            "loss: 0.006306  [32064/60000]\n",
            "loss: 0.008512  [38464/60000]\n",
            "loss: 0.007573  [44864/60000]\n",
            "loss: 0.008832  [51264/60000]\n",
            "loss: 0.005477  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.4%, Avg loss: 0.644715 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.012587  [   64/60000]\n",
            "loss: 0.002966  [ 6464/60000]\n",
            "loss: 0.007226  [12864/60000]\n",
            "loss: 0.003355  [19264/60000]\n",
            "loss: 0.003548  [25664/60000]\n",
            "loss: 0.002688  [32064/60000]\n",
            "loss: 0.004537  [38464/60000]\n",
            "loss: 0.008820  [44864/60000]\n",
            "loss: 0.006693  [51264/60000]\n",
            "loss: 0.005042  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.5%, Avg loss: 0.672384 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.017119  [   64/60000]\n",
            "loss: 0.002606  [ 6464/60000]\n",
            "loss: 0.003482  [12864/60000]\n",
            "loss: 0.026893  [19264/60000]\n",
            "loss: 0.001719  [25664/60000]\n",
            "loss: 0.088099  [32064/60000]\n",
            "loss: 0.023560  [38464/60000]\n",
            "loss: 0.007052  [44864/60000]\n",
            "loss: 0.005861  [51264/60000]\n",
            "loss: 0.011522  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.6%, Avg loss: 0.708406 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to find and display three errors\n",
        "def display_errors(model, dataloader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    errors = 0  # Counter for errors\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, targets in dataloader:\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "            for i in range(len(predictions)):\n",
        "                if predictions[i] != targets[i]:  # Check for misclassification\n",
        "                    img = data[i].squeeze(0)  # Get the image\n",
        "                    ground_truth = targets[i].item()\n",
        "                    prediction = predictions[i].item()\n",
        "\n",
        "                    # Display the misclassified image\n",
        "                    plt.imshow(img.cpu().numpy(), cmap=\"gray\")\n",
        "                    plt.title(f\"Ground Truth: {ground_truth}, Prediction: {prediction}\")\n",
        "                    plt.axis(\"off\")\n",
        "                    plt.show()\n",
        "\n",
        "                    errors += 1\n",
        "                    if errors == 3:  # Stop after displaying 3 errors\n",
        "                        return\n",
        "\n",
        "display_errors(model, test_dataloader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1250
        },
        "id": "-WFAjQC8kvlM",
        "outputId": "707822d6-7fc0-4eb7-c222-98e275c163ac"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Disscussion of Errors:**\n",
        "</br>\n",
        "The errors show cases where the model misclassified digits, likely because the images were blurry, poorly written, or had features that looked like another digit (e.g., a “4” looking like a “9”). Some mistakes might also be due to the images being skewed or off-center. These seem like reasonable errors since the dataset might not include enough examples of these edge cases, and the model struggles to generalize perfectly. Improving the dataset or preprocessing could help reduce these mistakes."
      ],
      "metadata": {
        "id": "ZTcBbw9mlrcn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLBUa_weQhh7"
      },
      "source": [
        "Read more about [Saving & Loading your\n",
        "model](saveloadrun_tutorial.html).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}